---
layout:     post
title:      会被当成会计师的Pandas入门(三)
subtitle:   使用列表的方法不误正业的作者是人间之屑
date:       2018-04-28
author:     Max
header-img: img/post-bg-rixi11.jpg
catalog: true
tags:
    - Python
    - 爬虫
    - Pandas
    - 科学计算
---

## 前言

真的真的做不到更新了，
因为加拿大这里的日常，我tm生物钟已经彻底乱掉了，
晚上七点钟外面阳光明媚你可信？看来得天天熬夜了的说

上周一整周摸鱼刷咸鱼题目，然后做题炸鱼被反炸
？？？
【上面说了这么多，唯一想要表达的观点就是我没法保持更新了哭哭】

今天可是重头戏了，终于终于要使用Excel表格输入输出了的x
~~你这样是会被当成会计师的辣~~

## 0x01 导入导出

Pandas滋瓷读写的文件格式有很多很多很多，平时我们也就用下面这几个：
- Excel
- CSV
- json
- html
  
等等，你json和html不用BeautifulSoup竟然用Pandas？害怕了......
这里有太多的读取方法了，也没有必要去一个一个记，官网上面其实都是有的
[Pandas读写文件表-Pandas官方教程](http://pandas.pydata.org/pandas-docs/stable/io.html)

这里我来读取一下我们学校的Excel计划表格做一个栗子吧
首先我先来使用Excel 2017打开一下，看一下正常的情况下这个表格应该是什么样子的:
![偷偷告诉你我把我原来学校给脱裤了嘻嘻嘻](https://upload-images.jianshu.io/upload_images/10219317-ff0168784da32b2a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

接下来我们使用Pandas来读取一下：
```
>>> xlsx = pd.ExcelFile(r'C:\Users\15806.DESKTOP-A9HK574\Documents\复件 2016-2017[数据删除]常规工作安排2016.8.23.xls')
>>> df = pd.read_excel(xlsx)
>>> df
                                   2012-2013学年学校常规工作安排         Unnamed: 1
NaN                                                NaN          2012.8.12
月份                                                工作内容               责任处室
8月                             学校纪念日（1942年8月3日 陈盛馨殉难日）                各处室
NaN                                  党政研讨会，办公室、各部门准备材料                各处室
NaN                                         “创先争优”工作部署                 党委
NaN                           《廉政准则》贯彻执行情况专项检查工作自查自纠阶段                 党委
NaN                        新教师报到和岗前培训，并办理各种保险、证件、工资等手续      办公室、教务处、\n德育处
NaN                                            全校安全大检查            校安全领导小组
NaN                                           总务处工作研讨会                总务处
NaN                                       设备、设施的修缮和补充；                总务处
NaN                                            学校绿化的维护                总务处
NaN                                   游泳池清洗及篮球网、排球网的添置                总务处
NaN                升旗杆拉线更新，准备新国旗、校旗（每一学年开学式用新旗，一年更换一次）                总务处
NaN                            召集物业、超市、食堂负责人召开新学年工作准备会                总务处
NaN                                     食堂、超市开学前准备工作检查                总务处
NaN                                         教师用房的准备与调整                总务处
NaN                    检查、清洗、送检学校饮水系统的纯净水，保证饮水系统开学正常使用                总务处
NaN                    对教室风扇和学生宿舍空调、风扇进行全面检查、维修，保证正常使用                总务处
NaN                                  消杀蚊、蝇、虫，做好卫生的整治工作                总务处
NaN                                             全校性的检查                总务处
NaN                                       每月对物业人员的测评工作                总务处
NaN      检查食堂、超市工作人员证照是否符合国家有关规定，杜绝无证上岗，核查食堂、超市菜品、商品价格                总务处
NaN                                       毕业生领取档案、转团关系        德育处  校团委学生会
NaN                                            初三学生返校日            教务处、德育处
NaN                                        初一新生摸底考试、分班                教务处
NaN                               初中部教研组临时负责人及其他备课组长例会                教务处
NaN                                        高一新生、高二文理分班            教务处、年段长
NaN                                             编排学生宿舍                德育处
NaN                                           高中教研组长会议                教务处
NaN                                   新学期欢迎标语的制作、宣传栏更换                德育处
..                                                 ...                ...
#这里也可以直接写read_excel来读取数据
xlsx = pd.read_excel(r'C:\Users\15806.DESKTOP-A9HK574\Documents\复件 2016-2017[数据删除]常规工作安排2016.8.23.xls')
```
感觉.....效果·不是太好？
emmmmmmm

最后还是得借用莫烦大大的csv【捂脸】
示范档案下载 - [student.csv](https://github.com/MorvanZhou/tutorials/blob/master/numpy%26pandas/15_read_to/student.csv)
```
>>> csv = pd.read_csv(r'C:\Users\15806.DESKTOP-A9HK574\Desktop\student.csv')
>>> csv
    Student ID  name   age  gender
0         1100  Kelly   22  Female
1         1101    Clo   21  Female
2         1102  Tilly   22  Female
3         1103   Tony   24    Male
4         1104  David   20    Male
5         1105  Catty   22  Female
6         1106      M    3  Female
7         1107      N   43    Male
8         1108      A   13    Male
9         1109      S   12    Male
10        1110  David   33    Male
11        1111     Dw    3  Female
12        1112      Q   23    Male
13        1113      W   21  Female
```
接下来我把它分别保存为xls和pickle文件
```
>>> csv.to_excel(r'C:\Users\15806.DESKTOP-A9HK574\Desktop\student.xls')
>>> csv.to_pickle(r'C:\Users\15806.DESKTOP-A9HK574\Desktop\student.pickle')
```
顺便给大家看一下效果：
![2.PNG](https://upload-images.jianshu.io/upload_images/10219317-b4ab70c8e4471186.PNG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

顺便给大家推广一下我记忆这些命令的规律：
- 从什么类型读入，就pd.read_类型名(文件路径)
- 用什么类型导出，就pd.to_类型名(文件路径)

## 0x02 concat合并数据
 
嘻嘻嘻，合并数据，全部转换成txt然后重新readlines就行了
【  恶  臭  不  堪  】
好了好了首先要介绍一下方法concat，这个方法可以从横向纵向和其他奇奇怪怪的向来合并多个的DataFrame
pd.concat([列表，用来存放要合并的df的名字]，axis=需要合并的维度)
axis=0是竖向合并（columns一样，index边长），
axis=1是横向合并（index一样，columns边长）。
首先我们创建三个不同的DataFrame，然后是用concat来合并一下
```
df1 = pd.DataFrame(np.ones((3,4))*0, columns=['a','b','c','d'])
df2 = pd.DataFrame(np.ones((3,4))*1, columns=['a','b','c','d'])
df3 = pd.DataFrame(np.ones((3,4))*2, columns=['a','b','c','d'])
>>> df1
     a    b    c    d
0  0.0  0.0  0.0  0.0
1  0.0  0.0  0.0  0.0
2  0.0  0.0  0.0  0.0
>>> df2
     a    b    c    d
0  1.0  1.0  1.0  1.0
1  1.0  1.0  1.0  1.0
2  1.0  1.0  1.0  1.0
>>> df3
     a    b    c    d
0  2.0  2.0  2.0  2.0
1  2.0  2.0  2.0  2.0
2  2.0  2.0  2.0  2.0
>>> print(pd.concat([df1,df2,df3],axis=0))
     a    b    c    d
0  0.0  0.0  0.0  0.0
1  0.0  0.0  0.0  0.0
2  0.0  0.0  0.0  0.0
0  1.0  1.0  1.0  1.0
1  1.0  1.0  1.0  1.0
2  1.0  1.0  1.0  1.0
0  2.0  2.0  2.0  2.0
1  2.0  2.0  2.0  2.0
2  2.0  2.0  2.0  2.0
>>> print(pd.concat([df1,df2,df3],axis=1))
     a    b    c    d    a    b    c    d    a    b    c    d
0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  2.0  2.0  2.0  2.0
1  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  2.0  2.0  2.0  2.0
2  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  2.0  2.0  2.0  2.0
```
哎，如果现在访问合并后的列表[0]，既不是有三个值
强迫症睿智们就很难受了，他们表示要重新排列！
把concat里面的ignore_index打开就行了【打开的意思就是把值设置为true，一般情况下为false，也就是关闭】

```
>>> print(pd.concat([df1,df2,df3],axis=0,ignore_index=True))
     a    b    c    d
0  0.0  0.0  0.0  0.0
1  0.0  0.0  0.0  0.0
2  0.0  0.0  0.0  0.0
3  1.0  1.0  1.0  1.0
4  1.0  1.0  1.0  1.0
5  1.0  1.0  1.0  1.0
6  2.0  2.0  2.0  2.0
7  2.0  2.0  2.0  2.0
8  2.0  2.0  2.0  2.0
```

**处理列表之间的不同值-join[ ]**

上面的结果是仅限于同样形状的DataFrame合并，但是如果是不同的形状呢？这个时候就可以考虑一下join[ ]【虽然会有很多很多讨厌的NaN但是我们可以用上一次介绍的pd.fillna()方法把NaN替换成你想要的值啊】
join有两种用法：outer 和 inner
- join='outer'为预设值，因此未设定任何参数时，函数默认join='outer'。此方式是依照column来做纵向合并，有相同的column上下合并在一起，其他独自的column个自成列，原本没有值的位置皆以NaN填充。
也就是说，有相同列标签的合并，没有的就另外列一一行
- join='inner'只合并有相同标签的列，会抛弃其他单独的列

join是和，join就是重叠部分了噗嗤
```
>>> #定义资料集
... df1 = pd.DataFrame(np.ones((3,4))*0, columns=['a','b','c','d'], index=[1,2,3])
>>> df2 = pd.DataFrame(np.ones((3,4))*1, columns=['b','c','d','e'], index=[2,3,4])
>>> df1
     a    b    c    d
1  0.0  0.0  0.0  0.0
2  0.0  0.0  0.0  0.0
3  0.0  0.0  0.0  0.0
>>> df2
     b    c    d    e
2  1.0  1.0  1.0  1.0
3  1.0  1.0  1.0  1.0
4  1.0  1.0  1.0  1.0
>>> res = pd.concat([df1, df2], axis=0, join='outer')
>>> res
     a    b    c    d    e
1  0.0  0.0  0.0  0.0  NaN
2  0.0  0.0  0.0  0.0  NaN
3  0.0  0.0  0.0  0.0  NaN
2  NaN  1.0  1.0  1.0  1.0
3  NaN  1.0  1.0  1.0  1.0
4  NaN  1.0  1.0  1.0  1.0

#df1没有e这一列所有全部用NaN填充
#df2没有a这一列所以全部用NaN填充

>>> res = pd.concat([df1, df2], axis=1, join='outer')
>>> res
     a    b    c    d    b    c    d    e
1  0.0  0.0  0.0  0.0  NaN  NaN  NaN  NaN
2  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0
3  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0
4  NaN  NaN  NaN  NaN  1.0  1.0  1.0  1.0

#df1没有4这一行所以全部用NaN来填充
#df2没有1这一行所以全部用NaN来填充

# ----------按照inner来合并----------
>>> res = pd.concat([df1, df2], axis=1, join='inner')
>>> res
     a    b    c    d    b    c    d    e
2  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0
3  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0

#df1和df2重叠的行只有2,3，所以1和4就被舍去了

>>> res = pd.concat([df1, df2], axis=0, join='inner')
>>> res
     b    c    d
1  0.0  0.0  0.0
2  0.0  0.0  0.0
3  0.0  0.0  0.0
2  1.0  1.0  1.0
3  1.0  1.0  1.0
4  1.0  1.0  1.0

#同理，因为重叠的列是b、c、d，所以a和e也被舍去了
``` 

**熟悉的列表append( )方法**
用列表这个久了，append死熟了，
在这里合并列表还要用concat什么的烦死了，为什么不是意思append？
想象一下DataFrame中的数据都是以一个长条形状的内存空间来储存的【详细参照我的两篇文章：[2018-03-18-数学不好的Scipy入门（一）](https://www.jianshu.com/p/9ade89303034)  [2018-03-21-半小时搞懂内存，指针和变量的关系](https://www.jianshu.com/p/d47a0834fd47)】
使用append就像是把数据直接加在了一个DataFrame条条的下面：
```
>>> res = df1.append(df2)
>>> res
     a    b    c    d
0  0.0  0.0  0.0  0.0
1  0.0  0.0  0.0  0.0
2  0.0  0.0  0.0  0.0
0  1.0  1.0  1.0  1.0
1  1.0  1.0  1.0  1.0
2  1.0  1.0  1.0  1.0

#如果append多个值就写一个列表就行了
>>> res = df1.append([df2, df3])
>>> res
     a    b    c    d
0  0.0  0.0  0.0  0.0
1  0.0  0.0  0.0  0.0
2  0.0  0.0  0.0  0.0
0  1.0  1.0  1.0  1.0
1  1.0  1.0  1.0  1.0
2  1.0  1.0  1.0  1.0
0  1.0  1.0  1.0  1.0
1  1.0  1.0  1.0  1.0
2  1.0  1.0  1.0  1.0
```
啊~熟悉的操作啊，
如果你只想每次添加一行嘛......为什么不用series呢？

值得一提的是就算你append进去一个Series进去也是可以的，但是必须重置index，不然会出故障的嗝
```
>>> s1
a    1
b    2
c    3
d    4
dtype: int64
>>> df1.append(s1)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "D:\Users\15806.DESKTOP-A9HK574\Anaconda\lib\site-packages\pandas\core\frame.py", line 4517, in append
    raise TypeError('Can only append a Series if ignore_index=True'
TypeError: Can only append a Series if ignore_index=True or if the Series has a name
>>> res =df1.append(s1,ignore_index=True)
>>> res
     a    b    c    d
0  0.0  0.0  0.0  0.0
1  0.0  0.0  0.0  0.0
2  0.0  0.0  0.0  0.0
3  1.0  2.0  3.0  4.0
```

## 后记
这篇稿是上周写好的，结果上周都没有更新woc
高斯写了三篇，感觉对于数学hopeness了，呕
祈祷我明天会记得写教程吧【发誓这周末不碰math，考完Gauss不碰滑铁卢的任何考卷一个月了】

~~不行啊手痒啊~~

## 最后的最后
[作者已经飞奔过去更新Blog了你怎么还不进来看看啊啊](https://0xc000005.github.io/)

